{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "audo-denoising.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Listen to some samples"
      ],
      "metadata": {
        "id": "eIw7ddjLnE4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "ipd.Audio(\"../input/clean-data/clean_trainset_28spk_wav/p226_001.wav\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-02T12:21:39.876566Z",
          "iopub.execute_input": "2022-05-02T12:21:39.876842Z",
          "iopub.status.idle": "2022-05-02T12:21:39.890987Z",
          "shell.execute_reply.started": "2022-05-02T12:21:39.876815Z",
          "shell.execute_reply": "2022-05-02T12:21:39.890224Z"
        },
        "trusted": true,
        "id": "eVDUeEemnE4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "ipd.Audio(\"../input/noisy-data/noisy_trainset_28spk_wav/p226_001.wav\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-02T12:21:40.203423Z",
          "iopub.execute_input": "2022-05-02T12:21:40.203877Z",
          "iopub.status.idle": "2022-05-02T12:21:40.215662Z",
          "shell.execute_reply.started": "2022-05-02T12:21:40.203827Z",
          "shell.execute_reply": "2022-05-02T12:21:40.214805Z"
        },
        "trusted": true,
        "id": "9-Mx4WB_nE4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read data"
      ],
      "metadata": {
        "id": "Y-AMjf0fnE4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "clean_wavs_path = glob.glob('../input/clean-data/clean_trainset_28spk_wav/*.wav')\n",
        "noisy_wavs_path = glob.glob('../input/noisy-data/noisy_trainset_28spk_wav/*.wav')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-02T12:21:40.486697Z",
          "iopub.execute_input": "2022-05-02T12:21:40.487172Z",
          "iopub.status.idle": "2022-05-02T12:21:40.541571Z",
          "shell.execute_reply.started": "2022-05-02T12:21:40.487122Z",
          "shell.execute_reply": "2022-05-02T12:21:40.54094Z"
        },
        "trusted": true,
        "id": "som3HIpAnE4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    target_sample_rate=48000\n",
        "    duration=4\n",
        "    n_fft=1024\n",
        "    hop_length=512\n",
        "    n_mels=64\n",
        "    batch_size=128\n",
        "    learning_rate=1e-6\n",
        "    epochs=6"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-02T12:21:41.247796Z",
          "iopub.execute_input": "2022-05-02T12:21:41.248333Z",
          "iopub.status.idle": "2022-05-02T12:21:41.253485Z",
          "shell.execute_reply.started": "2022-05-02T12:21:41.248298Z",
          "shell.execute_reply": "2022-05-02T12:21:41.252512Z"
        },
        "trusted": true,
        "id": "gd8ECSJXnE4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, clean_data_path, noisy_data_path, transform=None,\n",
        "                 target_sample_rate=config.target_sample_rate, duration=config.duration):\n",
        "        self.root_clean = clean_data_path\n",
        "        self.root_noisy = noisy_data_path\n",
        "        self.transform = transform\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "        self.num_samples = target_sample_rate*duration\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.root_clean)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        audio_path_clean = self.root_clean[index]\n",
        "        audio_path_noisy = self.root_noisy[index]\n",
        "        \n",
        "        signal, sr = torchaudio.load(audio_path_clean)\n",
        "        signal_noisy, sr_noisy = torchaudio.load(audio_path_noisy)\n",
        "        if sr != self.target_sample_rate:\n",
        "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
        "            signal = resampler(signal)\n",
        "            signal_noisy = resampler(signal_noisy)\n",
        "        \n",
        "        if signal.shape[0] > 1:\n",
        "            signal = torch.mean(signal, axis=0, keepdim=True)\n",
        "        \n",
        "        if signal_noisy.shape[0] > 1:\n",
        "            signal_noisy = torch.mean(signal_noisy, axis=0, keepdim=True)\n",
        "        \n",
        "        if signal.shape[1] > self.num_samples:\n",
        "            signal = signal[:, :self.num_samples]\n",
        "            \n",
        "        if signal_noisy.shape[1] > self.num_samples:\n",
        "            signal_noisy = signal_noisy[:, :self.num_samples]\n",
        "        \n",
        "        if signal.shape[1] < self.num_samples:\n",
        "            num_missing_samples = self.num_samples - signal.shape[1]\n",
        "            signal = F.pad(signal, (0, num_missing_samples))\n",
        "            \n",
        "        if signal_noisy.shape[1] < self.num_samples:\n",
        "            num_missing_samples = self.num_samples - signal_noisy.shape[1]\n",
        "            signal_noisy = F.pad(signal_noisy, (0, num_missing_samples))\n",
        "        \n",
        "        mel = self.transform(signal)\n",
        "        mel_noisy = self.transform(signal_noisy)\n",
        "        #print(mel.shape)\n",
        "        image = mel / torch.abs(mel).max()\n",
        "        return mel, mel_noisy#, signal_noisy"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-02T12:21:41.496601Z",
          "iopub.execute_input": "2022-05-02T12:21:41.496875Z",
          "iopub.status.idle": "2022-05-02T12:21:41.513045Z",
          "shell.execute_reply.started": "2022-05-02T12:21:41.496846Z",
          "shell.execute_reply": "2022-05-02T12:21:41.512352Z"
        },
        "trusted": true,
        "id": "wKUpg74qnE41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=config.target_sample_rate,\n",
        "                                                      n_fft=config.n_fft, \n",
        "                                                      hop_length=config.hop_length, \n",
        "                                                      n_mels=config.n_mels)\n",
        "\n",
        "\n",
        "test_clean = clean_wavs_path[:10]\n",
        "test_noisy = noisy_wavs_path[:10]\n",
        "\n",
        "training_dataset = CustomDataset(clean_wavs_path[10:11000], noisy_wavs_path[10:11000], mel_spectrogram)\n",
        "validation_dataset = CustomDataset(clean_wavs_path[11000:], noisy_wavs_path[11000:], mel_spectrogram)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-02T12:21:41.738833Z",
          "iopub.execute_input": "2022-05-02T12:21:41.739127Z",
          "iopub.status.idle": "2022-05-02T12:21:41.748009Z",
          "shell.execute_reply.started": "2022-05-02T12:21:41.739081Z",
          "shell.execute_reply": "2022-05-02T12:21:41.747353Z"
        },
        "trusted": true,
        "id": "uKizbe0inE46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(training_dataset, batch_size=config.batch_size)\n",
        "validloader = DataLoader(validation_dataset, batch_size=config.batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-02T12:21:41.982376Z",
          "iopub.execute_input": "2022-05-02T12:21:41.983429Z",
          "iopub.status.idle": "2022-05-02T12:21:41.989064Z",
          "shell.execute_reply.started": "2022-05-02T12:21:41.983379Z",
          "shell.execute_reply": "2022-05-02T12:21:41.987894Z"
        },
        "trusted": true,
        "id": "C4t37a16nE4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "a = iter(trainloader)\n",
        "images = a.next()\n",
        "\n",
        "\n",
        "def imageshow_ax(image, ax):\n",
        "    npimage = image.numpy()\n",
        "    ax.imshow(np.transpose(npimage, (1, 2, 0)))\n",
        "\n",
        "plt.figure(figsize=(15, 9))\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "for image_number, ax in enumerate(axs.ravel()):\n",
        "    imageshow_ax(torchvision.utils.make_grid(images[image_number][:4]), ax)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-02T12:21:43.586328Z",
          "iopub.execute_input": "2022-05-02T12:21:43.586575Z",
          "iopub.status.idle": "2022-05-02T12:21:43.897858Z",
          "shell.execute_reply.started": "2022-05-02T12:21:43.586543Z",
          "shell.execute_reply": "2022-05-02T12:21:43.896949Z"
        },
        "trusted": true,
        "id": "QP-JhGaUnE5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "v4cibISvnE5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self, chnls_in=1, chnls_out=1):\n",
        "        super(UNetGenerator, self).__init__()\n",
        "        self.down_conv_layer_1 = DownConvBlock(chnls_in, 64, norm=False)\n",
        "        self.down_conv_layer_2 = DownConvBlock(64, 128)\n",
        "        self.down_conv_layer_3 = DownConvBlock(128, 256)\n",
        "        self.down_conv_layer_4 = DownConvBlock(256, 256, dropout=0.5)\n",
        "        self.down_conv_layer_5 = DownConvBlock(256, 256, dropout=0.5)\n",
        "        self.down_conv_layer_6 = DownConvBlock(256, 256, dropout=0.5)\n",
        "\n",
        "        self.up_conv_layer_1 = UpConvBlock(256, 256, kernel_size=(2,3), stride=2, padding=0, dropout=0.5)# 256+256 6 5 kernel_size=(2, 3), stride=2, padding=0\n",
        "        self.up_conv_layer_2 = UpConvBlock(512, 256, kernel_size=(2,3), stride=2, padding=0, dropout=0.5) # 256+256 1 4\n",
        "        self.up_conv_layer_3 = UpConvBlock(512, 256, kernel_size=(2,3), stride=2, padding=0, dropout=0.5) # 2 3\n",
        "        self.up_conv_layer_4 = UpConvBlock(512, 128, dropout=0.5) # 3 2\n",
        "        self.up_conv_layer_5 = UpConvBlock(256, 64) # 4 1\n",
        "        self.up_conv_layer_6 = UpConvBlock(512, 128)\n",
        "        self.up_conv_layer_7 = UpConvBlock(256, 64)\n",
        "        self.upsample_layer = nn.Upsample(scale_factor=2)\n",
        "        self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
        "        self.conv_layer_1 = nn.Conv2d(128, chnls_out, 4, padding=1)\n",
        "        self.activation = nn.Tanh()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #print('x', x.shape)\n",
        "        enc1 = self.down_conv_layer_1(x) # [4, 64, 32, 188]\n",
        "        print('1', enc1.shape)\n",
        "        enc2 = self.down_conv_layer_2(enc1) # [4, 128, 16, 94]\n",
        "        print('2', enc2.shape)\n",
        "        enc3 = self.down_conv_layer_3(enc2) # [4, 256, 8, 47]\n",
        "        print('3', enc3.shape)\n",
        "        enc4 = self.down_conv_layer_4(enc3) # [4, 256, 4, 23]\n",
        "        print('4', enc4.shape)\n",
        "        enc5 = self.down_conv_layer_5(enc4) # [4, 256, 2, 11]\n",
        "        print('5', enc5.shape)\n",
        "        enc6 = self.down_conv_layer_6(enc5) # [4, 256, 1, 5]\n",
        "        #print('6', enc6.shape)\n",
        " \n",
        "        dec1 = self.up_conv_layer_1(enc6, enc5)# enc6: 256 + enc5: 256 [4, 512, 2, 11]\n",
        "        #print('d1', dec1.shape)\n",
        "        dec2 = self.up_conv_layer_2(dec1, enc4)# enc4: 256 + dec1=enc5*2: [4, 512, 4, 23]\n",
        "        #print('d2', dec2.shape)\n",
        "        dec3 = self.up_conv_layer_3(dec2, enc3)# enc3: 256 + dec2=enc4*2: [4, 512, 8, 47]\n",
        "        #print('d3', dec3.shape)\n",
        "        dec4 = self.up_conv_layer_4(dec3, enc2)# enc2: 128 + dec3=enc3*2: [4, 256, 16, 94]\n",
        "        #print('d4', dec4.shape)\n",
        "        dec5 = self.up_conv_layer_5(dec4, enc1)# enc1: 64 + dec4=enc1*2: [4, 128, 32, 188]\n",
        "        #print('d5', dec5.shape)\n",
        "      \n",
        "        final = self.upsample_layer(dec5)\n",
        "        final = self.zero_pad(final)\n",
        "        final = self.conv_layer_1(final)\n",
        "        #print(final.shape)\n",
        "        return final\n",
        "\n",
        "class UpConvBlock(nn.Module):\n",
        "    def __init__(self, ip_sz, op_sz, kernel_size=4, stride= 2, padding=1 ,dropout=0.0):\n",
        "        super(UpConvBlock, self).__init__()\n",
        "        self.layers = [\n",
        "            nn.ConvTranspose2d(ip_sz, op_sz, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "            nn.InstanceNorm2d(op_sz),\n",
        "            nn.ReLU(),\n",
        "        ]\n",
        "        if dropout:\n",
        "            self.layers += [nn.Dropout(dropout)]\n",
        "    def forward(self, x, enc_ip):\n",
        "        x = nn.Sequential(*(self.layers))(x)\n",
        "        #print('x', x.shape)\n",
        "        #print('enc', enc_ip.shape)\n",
        "        op = torch.cat((x, enc_ip), 1)\n",
        "        return op\n",
        "\n",
        "\n",
        "class DownConvBlock(nn.Module):\n",
        "    def __init__(self, ip_sz, op_sz, kernel_size=4, norm=True, dropout=0.0):\n",
        "        super(DownConvBlock, self).__init__()\n",
        "        self.layers = [nn.Conv2d(ip_sz, op_sz, kernel_size, 2, 1)]\n",
        "        if norm:\n",
        "            self.layers.append(nn.InstanceNorm2d(op_sz))\n",
        "        self.layers += [nn.LeakyReLU(0.2)]\n",
        "        if dropout:\n",
        "            self.layers += [nn.Dropout(dropout)]\n",
        "    def forward(self, x):\n",
        "        op = nn.Sequential(*(self.layers))(x)\n",
        "        return op\n",
        "    \n",
        "model = UNetGenerator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-02T12:21:43.907004Z",
          "iopub.execute_input": "2022-05-02T12:21:43.907314Z",
          "iopub.status.idle": "2022-05-02T12:21:43.998497Z",
          "shell.execute_reply.started": "2022-05-02T12:21:43.907272Z",
          "shell.execute_reply": "2022-05-02T12:21:43.997619Z"
        },
        "trusted": true,
        "id": "IZ-ZI0z9nE5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(dataloader, model, epoch, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for i, (clean, noisy) in enumerate(tqdm(dataloader)):\n",
        "        clean = clean.to(device)\n",
        "        noisy = noisy.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = model(noisy)\n",
        "        curr_loss = loss_fn(pred, clean)\n",
        "        curr_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += curr_loss\n",
        "        if i % 1000 == 0:\n",
        "            print('[Epoch number : %d, Mini-batches: %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, total_loss / 200))\n",
        "            total_loss = 0.0\n",
        "            \n",
        "def val(dataloader, model, epoch, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    print('-------------------------')\n",
        "    with torch.no_grad():\n",
        "        for i, (clean, noisy) in enumerate(tqdm(dataloader)):\n",
        "            clean = clean.to(device)\n",
        "            noisy = noisy.to(device)\n",
        "        \n",
        "            output = model(noisy)\n",
        "            loss = loss_fn(output, clean)\n",
        "            total_loss += loss\n",
        "            if i % 100 == 0:\n",
        "                print('[Valid Epoch number : %d, Mini-batches: %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, total_loss / 200))\n",
        "                total_loss = 0.0\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-27T10:04:10.785142Z",
          "iopub.execute_input": "2022-04-27T10:04:10.785623Z",
          "iopub.status.idle": "2022-04-27T10:04:10.799833Z",
          "shell.execute_reply.started": "2022-04-27T10:04:10.785507Z",
          "shell.execute_reply": "2022-04-27T10:04:10.79874Z"
        },
        "trusted": true,
        "id": "wTo6fGeenE5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "loss_fn = torch.nn.functional.mse_loss\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "model = UNetGenerator().to(device)\n",
        "\n",
        "for epoch in range(config.epochs):\n",
        "    train(trainloader, model, epoch, loss_fn, optimizer, device)\n",
        "    val(validloader, model, epoch, loss_fn, device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-27T10:04:10.801778Z",
          "iopub.execute_input": "2022-04-27T10:04:10.802266Z",
          "iopub.status.idle": "2022-04-27T14:22:29.842528Z",
          "shell.execute_reply.started": "2022-04-27T10:04:10.802218Z",
          "shell.execute_reply": "2022-04-27T14:22:29.838683Z"
        },
        "trusted": true,
        "id": "0_1AJeyHnE5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './working/model'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-27T14:25:48.573643Z",
          "iopub.execute_input": "2022-04-27T14:25:48.573982Z",
          "iopub.status.idle": "2022-04-27T14:25:48.622417Z",
          "shell.execute_reply.started": "2022-04-27T14:25:48.573945Z",
          "shell.execute_reply": "2022-04-27T14:25:48.621329Z"
        },
        "trusted": true,
        "id": "8jWEH9bKnE5R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}